***DATA SCIENCE:***

***data*** ---> collection of entire data

***information (or) insight***  --> collection of specific data

data science  --> from ourself collecting amount of data ,processing ,analyzing it and making insights or prediction

statistics  --->mostly used in data science



***KPIs:***

***KEY PERFORMANCE INDICATOR***

* KPI is a measurable value that shows how well a company, a project ,a process id performing.
* KPI is a number whether a process is success or not .



***WHY KPI NEEDED?***

* make goals measurable
* help in decision making
* track the process over time
* help in finding problems



***TYPES OF KPIs***

* Quantitative KIPs -> countable
* Qualitative KPIs  -> measurable   eg: customer reviews
* Leading KPIs  ->
* Lagging KPIs -> it stores history of  KPIs
* Operational KPIs



***BUSINESS PROBLEM:***

A business problem is a challenge or an opportunity . A company faces which needs data to understand, solve or improve.

field --> dress shop or textiles

 1. customer need will change as per the trend

 2. they should check the trend always

 3. customer should get attract by the color combinations

 4. handloom sarees , cloth material



***DATA ANALYSIS CHECK : (mostly depends on sales)***

* sales drop
* sales per product
* customer buying pattern
* competitor price



fintech  -> financial technology combination of numerical and categorial numbers.



***DATA CLEANING:***

* data preprocessing step is known as data cleaning
* handling missing values and incorrect values  --> this is preprocessing



***There are 5 types:***

1. Missing values
2. duplicate
3. wrong data type
4. inconsistent test
5. feature engineering



***FEATURES ENGINEERING:***

Feature engineering is helps to creating better input features for models from raw data.



***TYPES OF FEATURES:***

1. Numerical transformation   -> scaling , binding
2. categorical encoding  -> separating gender wise
3. Day time features  -> date-month-year, 3x3 total 9 possibilities
4. aggrigated features  -> units consumed by one family
5. Interaction features  -> interact with other data eg : BMI calculated by height and weight



***E -COMMERCE DATA:***

1. order
2. delivery
3. offers
4. wishlist
5. add to cart
6. location
7. date
8. phone number
9. name
10. products
11. reviews
12. rating
13. quantity
14. price
15. coupon code
16. color
17. size
18. filters
19. brand
20. tracking



***EDA (Exploratory Data Analysis):***

* EDA with pandas
* EDA with numpy
* EDA with matplotlib
* EDA with seaborn



peak values -> trend

short period of time -> trend

longer period of time -> seasonality



***Exploratory datatypes:***

* how a data get trend , seasonality, varying, and deviated.
* from fixed data point how the data get deviated (or) varied is known as deviation.



***matplotlib (pictorial representations):***

1.line lot

2.dotplot

3.scatter plot

4.bar graph



legends  --> a small square boxes used to denote different variables.



IDE --> Integrated Development Environment



**characteristics :**

1. systematic process  ->

   2. data-centric  -> quality and accuracy  based

   3.iterative nature  -> until we achieve our best accuracy we iterate



***STEPS INVOLVED IN MODEL BUILDING:***

1.Problem definition  -> identification the problem in business

2.Data Collection     -> gathering the data for the problem

3.Preprocessing      -> cleaning data, handle missing values and address outlier(EDA , data cleaning)

4.Feature Engineering -> create meaningful variables that enhance model prediction

5.Model Selection     -> algorithm based on problem type and data characteristics

6.Training            -> fit the model to training data and optimise parameter

7.Evaluation          -> performance using validation sets and relevant metrics

8.Deployment          -> integrate the model into production environments

9.Monitoring          -> model performance and detect degradation overtime



***MACHINE LEARNING MODELS:***

***1.REGRESSION:***

It is a continuous prediction. eg : time, money, weight and heart rate  (it should be measurable).

These models predict continuous numeric outcomes by learning relationship between input features and output.

   a. linear

   b. logistic

***2.CLASSIFICATION:***

   a. Binary classification

   b. Tree based classification



1.Linear Regression:

   y=B(0)+B1X1+BnXn



2.Ridge Regression:\[L2] --> Regularization

   loss = summation(y-y^)2+lamda(summation B^2)



3.Lasso Regression:\[L1] --> Regularization

   loss = summation(y-y^)2+lamda(summation |B|)



AI - Artificial Intelligence man-made thinking power

MACHINE LEARNING - making the machine to learn the certain patterns

DATA SCIENCE - it helps in processing the data for best results depends on the seasonality, customer. analyzing the large set of data.

DEEP LEARNING - it is a specialized subset of ML that utilizes deep neural network to solve complex problems



***MODEL TRAINING:***

 two libraries SK-LEARN (Scikit learn) and TENSOR FLOW --> divided into two division classifier models amd regression models



***Using oops concept***

model is called using object

for eg: model = Random Forest()

        model.train



***LIBRARIES:***

import numpy as np   for numerical data

import pandas as pd   for tabulation

import matplotlib.pyplot as plt   for plotting

import seaborn as sns



raw data -> load (for loading we use pandas ) to concatenation we use function concat.

data.describe().T  --> for describing the numerical values.



***DATA VISUALIZATION:***

Representation of processed and cleaned data in a graphical or pictorial representation.



***GIT:***

* virtual control tools used for managing versions of the software or code

         -->GIT CL1 --> GIT Bash

* Git is a tree like structure.
* It runs locally on computer ,helps to track changes in source code and works offline.
* if someone commits the other persons error code then he/she would admit the blame
* GitHub helps in Hosting a website. It is an application for educational purpose not everybody use it for personal use.



***Basic Commands:***

-->Push

-->cOMMIT

-->pULL

-->Blame



Tree structure that stores the code of the software.



***Origin/Main***

L>B1

L>B2



***POWER BI :***

Power BI is used for visualization and report.



***SQL:***

Structured Query Language (independent letter case)

It has two types,

  1.DDL-->Data Definition Language  (to define the data (to create table ,rows and columns)

  2.DML-->Data Manipulation Language (used to change the data)



entities:

two types:

 1. Primary keys--> initialize defined keys (unique )

 2. Foreign key-->































 

